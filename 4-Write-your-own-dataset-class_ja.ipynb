{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データセットクラスを書いてみよう\n",
    "\n",
    "ここでは、Chainerにすでに用意されているCIFAR10のデータを取得する機能を使って、データセットクラスを自分で書いてみます。Chainerでは、データセットを表すクラスは以下の機能を持っていることが必要とされます。\n",
    "\n",
    "- データセット内のデータ数を返す`__len__`メソッド\n",
    "- 引数として渡される`i`に対応したデータもしくはデータとラベルの組を返す`get_example`メソッド\n",
    "\n",
    "その他のデータセットに必要な機能は、`chainer.dataset.DatasetMixin`クラスを継承することで用意できます。ここでは、`DatasetMixin`クラスを継承した**Data augmentation**機能のついたデータセットクラスを作成してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CIFAR10データセットクラスを書く"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from chainer import dataset\n",
    "from chainer.datasets import cifar\n",
    "\n",
    "class CIFAR10(dataset.DatasetMixin):\n",
    "\n",
    "    def __init__(self, train=True):\n",
    "        train_data, test_data = cifar.get_cifar10()\n",
    "        if train:\n",
    "            self.data = train_data\n",
    "        else:\n",
    "            self.data = test_data\n",
    "        self.train = train\n",
    "        self.random_crop = 4\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_example(self, i):\n",
    "        x, t = self.data[i]\n",
    "        if self.train:\n",
    "            x = x.transpose(1, 2, 0)\n",
    "            h, w, _ = x.shape\n",
    "            x_offset = np.random.randint(self.random_crop)\n",
    "            y_offset = np.random.randint(self.random_crop)\n",
    "            x = x[y_offset:y_offset + h - self.random_crop,\n",
    "                  x_offset:x_offset + w - self.random_crop]\n",
    "            if np.random.rand() > 0.5:\n",
    "                x = np.fliplr(x)\n",
    "            x = x.transpose(2, 0, 1)\n",
    "        return x, t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このクラスは、CIFAR10のデータのそれぞれに対し、\n",
    "\n",
    "- 32x32の大きさの中からランダムに28x28の領域をクロップ\n",
    "- 1/2の確率で左右を反転させる\n",
    "\n",
    "という加工を行っています。これによって、擬似的に学習データのバリエーションを増やすことができ、オーバーフィッティングを抑制することに役に立つことが知られています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 作成したデータセットクラスを使って学習を行う\n",
    "\n",
    "それではさっそくこの`CIFAR10`クラスを使って学習を行ってみましょう。以前使ったのと同じ畳み込み層のあるネットワークを使うことで、Data augmentationの効果がどの程度あるのかを調べてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/loss   main/accuracy  validation/main/loss  validation/main/accuracy  elapsed_time\n",
      "\u001b[J1           1.6131      0.408708       1.44266               0.476612                  5.72067       \n",
      "\u001b[J2           1.34159     0.515965       1.41165               0.489749                  10.9183       \n",
      "\u001b[J3           1.23198     0.559599       1.39705               0.505175                  16.1342       \n",
      "\u001b[J4           1.1645      0.582366       1.32884               0.528264                  21.3852       \n",
      "\u001b[J5           1.09811     0.607477       1.28315               0.544287                  27.0284       \n",
      "\u001b[J6           1.05643     0.62452        1.28018               0.541401                  32.5634       \n",
      "\u001b[J7           1.00531     0.641145       1.2171                0.568471                  37.8795       \n",
      "\u001b[J8           0.968023    0.65649        1.21219               0.567874                  43.0586       \n",
      "\u001b[J9           0.931772    0.667979       1.28827               0.548666                  48.3106       \n",
      "\u001b[J10          0.899743    0.682919       1.18176               0.578424                  53.6087       \n",
      "\u001b[J11          0.86674     0.692382       1.16917               0.592655                  58.7724       \n",
      "\u001b[J12          0.835844    0.702925       1.19858               0.577826                  63.9805       \n",
      "\u001b[J13          0.81801     0.710738       1.14162               0.596537                  69.1583       \n",
      "\u001b[J14          0.782713    0.722471       1.14886               0.598029                  74.3823       \n",
      "\u001b[J15          0.767482    0.725352       1.14146               0.603105                  79.5262       \n",
      "\u001b[J16          0.747419    0.735495       1.13159               0.605096                  84.6797       \n",
      "\u001b[J17          0.721501    0.744305       1.16848               0.600119                  89.8737       \n",
      "\u001b[J18          0.69928     0.753801       1.12323               0.615844                  95.1202       \n",
      "\u001b[J19          0.688468    0.757282       1.11716               0.621716                  100.341       \n",
      "\u001b[J20          0.668853    0.763564       1.13494               0.616939                  105.492       \n",
      "\u001b[J21          0.644467    0.770181       1.14956               0.617635                  110.671       \n",
      "\u001b[J22          0.629145    0.774848       1.16256               0.611365                  115.857       \n",
      "\u001b[J23          0.612882    0.782811       1.19387               0.60002                   121.011       \n",
      "\u001b[J24          0.600904    0.787652       1.16272               0.610768                  126.211       \n",
      "\u001b[J25          0.578069    0.794597       1.20512               0.614053                  131.37        \n",
      "\u001b[J26          0.572345    0.797255       1.3043                0.576831                  136.531       \n",
      "\u001b[J27          0.561421    0.799736       1.25337               0.603702                  141.698       \n",
      "\u001b[J28          0.54617     0.807138       1.22229               0.612361                  146.867       \n",
      "\u001b[J29          0.536871    0.810522       1.26931               0.601811                  152.077       \n",
      "\u001b[J30          0.52249     0.815201       1.26857               0.604498                  157.239       \n",
      "\u001b[J31          0.509204    0.819922       1.29924               0.596935                  162.546       \n",
      "\u001b[J32          0.493316    0.825544       1.31678               0.600119                  167.757       \n",
      "\u001b[J33          0.489657    0.826187       1.27389               0.613356                  172.98        \n",
      "\u001b[J34          0.480933    0.829265       1.30829               0.600219                  178.181       \n",
      "\u001b[J35          0.469764    0.832686       1.33865               0.607982                  183.333       \n",
      "\u001b[J36          0.461647    0.837788       1.36939               0.597631                  188.5         \n",
      "\u001b[J37          0.451122    0.840593       1.3658                0.592954                  193.671       \n",
      "\u001b[J38          0.438467    0.84245        1.37074               0.59992                   198.862       \n",
      "\u001b[J39          0.436629    0.84433        1.38142               0.60629                   204.027       \n",
      "\u001b[J40          0.431395    0.846011       1.46743               0.589769                  209.194       \n",
      "\u001b[J41          0.422334    0.850623       1.39346               0.598229                  214.367       \n",
      "\u001b[J42          0.410915    0.853873       1.41724               0.601413                  219.571       \n",
      "\u001b[J43          0.40611     0.856594       1.41332               0.599721                  224.707       \n",
      "\u001b[J44          0.401926    0.856014       1.50602               0.590963                  229.942       \n",
      "\u001b[J45          0.393555    0.860454       1.42571               0.604001                  235.139       \n",
      "\u001b[J46          0.390103    0.862436       1.435                 0.608081                  240.34        \n",
      "\u001b[J47          0.385783    0.863596       1.59362               0.584295                  245.605       \n",
      "\u001b[J48          0.382622    0.863116       1.53555               0.588376                  250.787       \n",
      "\u001b[J49          0.369083    0.869365       1.53436               0.595541                  255.952       \n",
      "\u001b[J50          0.364554    0.869918       1.55133               0.592655                  261.111       \n",
      "\u001b[J51          0.360852    0.873339       1.5961                0.591162                  266.262       \n",
      "\u001b[J52          0.358537    0.873339       1.54818               0.597333                  271.46        \n",
      "\u001b[J53          0.35118     0.874441       1.58509               0.588774                  276.616       \n",
      "\u001b[J54          0.351692    0.87516        1.61537               0.591162                  281.773       \n",
      "\u001b[J55          0.346829    0.876821       1.55253               0.592755                  287.068       \n",
      "\u001b[J56          0.342714    0.878241       1.61014               0.592954                  292.258       \n",
      "\u001b[J57          0.335292    0.882932       1.66906               0.589072                  297.498       \n",
      "\u001b[J58          0.322463    0.885503       1.64663               0.594646                  302.686       \n",
      "\u001b[J59          0.330319    0.881982       1.65096               0.598726                  307.893       \n",
      "\u001b[J60          0.322074    0.885884       1.68996               0.59156                   313.126       \n",
      "\u001b[J61          0.323773    0.887248       1.67                  0.588077                  318.311       \n",
      "\u001b[J62          0.316898    0.889385       1.77119               0.587381                  323.517       \n",
      "\u001b[J63          0.314077    0.887684       1.75878               0.588774                  328.681       \n",
      "\u001b[J64          0.310908    0.890425       1.73748               0.590665                  333.857       \n",
      "\u001b[J65          0.303083    0.894361       1.82357               0.586883                  339.041       \n",
      "\u001b[J87          0.249334    0.912372       2.11372               0.573746                  453.665       \n",
      "\u001b[J88          0.257844    0.911272       1.9426                0.587878                  458.831       \n",
      "\u001b[J89          0.260903    0.910746       2.03058               0.579817                  464.026       \n",
      "\u001b[J90          0.249624    0.913872       2.17242               0.579817                  469.207       \n",
      "\u001b[J91          0.249367    0.913912       2.04991               0.58539                   474.397       \n",
      "\u001b[J92          0.241657    0.914293       2.01541               0.596935                  479.625       \n",
      "\u001b[J93          0.250128    0.913523       2.05543               0.588276                  484.828       \n",
      "\u001b[J94          0.239814    0.915873       2.11122               0.582006                  490.004       \n",
      "\u001b[J95          0.246134    0.914693       2.17757               0.574045                  495.267       \n",
      "\u001b[J96          0.252484    0.913392       2.07868               0.585191                  500.471       \n",
      "\u001b[J97          0.237336    0.917999       1.97192               0.590466                  505.788       \n",
      "\u001b[J98          0.235652    0.918694       2.12191               0.584096                  511.003       \n",
      "\u001b[J99          0.245256    0.915693       2.0598                0.59375                   516.242       \n",
      "\u001b[J100         0.242065    0.917374       2.10748               0.586385                  521.41        \n"
     ]
    }
   ],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.datasets import cifar\n",
    "from chainer import iterators\n",
    "from chainer import optimizers\n",
    "from chainer import training\n",
    "from chainer.training import extensions\n",
    "\n",
    "# 前回と同じモデルを用意\n",
    "class MyModel(chainer.Chain):\n",
    "    \n",
    "    def __init__(self, n_out):\n",
    "        super(MyModel, self).__init__(\n",
    "            conv1=L.Convolution2D(None, 32, 3, 3, 1),\n",
    "            conv2=L.Convolution2D(32, 64, 3, 3, 1),\n",
    "            conv3=L.Convolution2D(64, 128, 3, 3, 1),\n",
    "            fc4=L.Linear(None, 1000),\n",
    "            fc5=L.Linear(1000, n_out)\n",
    "        )\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.conv1(x))\n",
    "        h = F.relu(self.conv2(h))\n",
    "        h = F.relu(self.conv3(h))\n",
    "        h = F.relu(self.fc4(h))\n",
    "        h = self.fc5(h)\n",
    "        return h\n",
    "\n",
    "batchsize = 64\n",
    "gpu_id = 0\n",
    "max_epoch = 100\n",
    "\n",
    "# 1. Dataset\n",
    "train, test = CIFAR10(), CIFAR10(train=False)\n",
    "\n",
    "# 2. Iterator\n",
    "train_iter = iterators.SerialIterator(train, batchsize)\n",
    "test_iter = iterators.SerialIterator(test, batchsize, False, False)\n",
    "\n",
    "# 3. Model\n",
    "model = MyModel(10)\n",
    "model = L.Classifier(model)\n",
    "model.to_gpu(gpu_id)\n",
    "\n",
    "# 4. Optimizer\n",
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(model)\n",
    "\n",
    "# 5. Updater\n",
    "updater = training.StandardUpdater(train_iter, optimizer, device=gpu_id)\n",
    "\n",
    "# 6. Trainer\n",
    "trainer = training.Trainer(updater, (max_epoch, 'epoch'), out='cifar10_result')\n",
    "\n",
    "trainer.extend(extensions.LogReport())\n",
    "trainer.extend(extensions.Evaluator(test_iter, model, device=gpu_id))\n",
    "trainer.extend(extensions.PrintReport(['epoch', 'main/loss', 'main/accuracy', 'validation/main/loss', 'validation/main/accuracy', 'elapsed_time']))\n",
    "trainer.extend(extensions.PlotReport(['main/loss', 'validation/main/loss'], x_key='epoch', file_name='loss.png'))\n",
    "trainer.extend(extensions.PlotReport(['main/accuracy', 'validation/main/accuracy'], x_key='epoch', file_name='accuracy.png'))\n",
    "trainer.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
