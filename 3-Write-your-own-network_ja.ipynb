{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 新しいネットワークを書いてみよう\n",
    "\n",
    "ここでは、MNISTデータセットではなくCIFAR10という32x32サイズの小さなカラー画像に10クラスのいずれかのラベルがついたデータセットを用いて、いろいろなモデルを自分で書いて試行錯誤する流れを体験してみます。\n",
    "\n",
    "| airplane | automobile | bird | cat | deer | dog | frog | horse | ship | truck |\n",
    "|:--------:|:----------:|:----:|:---:|:----:|:---:|:----:|:-----:|:----:|:-----:|\n",
    "| ![](https://www.cs.toronto.edu/~kriz/cifar-10-sample/airplane4.png) | ![](https://www.cs.toronto.edu/~kriz/cifar-10-sample/automobile4.png) | ![](https://www.cs.toronto.edu/~kriz/cifar-10-sample/bird4.png) | ![](https://www.cs.toronto.edu/~kriz/cifar-10-sample/cat4.png) | ![](https://www.cs.toronto.edu/~kriz/cifar-10-sample/deer4.png) | ![](https://www.cs.toronto.edu/~kriz/cifar-10-sample/dog4.png) | ![](https://www.cs.toronto.edu/~kriz/cifar-10-sample/frog4.png) | ![](https://www.cs.toronto.edu/~kriz/cifar-10-sample/horse4.png) | ![](https://www.cs.toronto.edu/~kriz/cifar-10-sample/ship4.png) | ![](https://www.cs.toronto.edu/~kriz/cifar-10-sample/truck4.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1. モデルの定義\n",
    "\n",
    "モデルは、`Chain`クラスを継承して定義します。ここでは、以前試した全結合層だけからなるネットワークではなく、畳込み層を持つネットワークを定義してみます。このモデルは3つの畳み込み層を持ち、2つの全結合層がそのあとに続いています。\n",
    "\n",
    "モデルの定義は主に2つのメソッドの定義によって行います。\n",
    "\n",
    "1. コンストラクタでモデルを構成するレイヤーを定義する\n",
    "    - この際、親クラス（`Chain`）のコンストラクタにキーワード引数として構成する`Link`オブジェクトを渡すことで`Optimizer`から捕捉可能な最適化対象のパラメータを持つレイヤをモデルに追加することができます。\n",
    "2. `()`アクセサでデータを受け取り、Forward計算を行う`__call__`メソッドを定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "\n",
    "class MyModel(chainer.Chain):\n",
    "    \n",
    "    def __init__(self, n_out):\n",
    "        super(MyModel, self).__init__(\n",
    "            conv1=L.Convolution2D(None, 32, 3, 3, 1),\n",
    "            conv2=L.Convolution2D(32, 64, 3, 3, 1),\n",
    "            conv3=L.Convolution2D(64, 128, 3, 3, 1),\n",
    "            fc4=L.Linear(None, 1000),\n",
    "            fc5=L.Linear(1000, n_out)\n",
    "        )\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.conv1(x))\n",
    "        h = F.relu(self.conv2(h))\n",
    "        h = F.relu(self.conv3(h))\n",
    "        h = F.relu(self.fc4(h))\n",
    "        h = self.fc5(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. 学習\n",
    "\n",
    "ここで、あとから別のモデルも簡単に同じ設定で訓練できるよう、`train`関数を定義しておきます。これは、モデルのオブジェクトを渡すと、中で`Trainer`を用いてCIFAR10データセットの画像を10クラスに分類するようにそのモデルを訓練する関数です。\n",
    "\n",
    "この`train`関数を用いて、上で定義した`MyModel`モデルを訓練してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/loss   main/accuracy  validation/main/loss  validation/main/accuracy  elapsed_time\n",
      "\u001b[J1           1.96901     0.264166       1.63314               0.36873                   22.0405       \n",
      "\u001b[J2           1.44139     0.462988       1.27741               0.544486                  42.2017       \n",
      "\u001b[J3           1.10484     0.613356       1.02218               0.644307                  62.1837       \n",
      "\u001b[J4           0.914587    0.683299       0.858129              0.71039                   82.2033       \n",
      "\u001b[J5           0.779879    0.737592       0.808558              0.739053                  102.283       \n",
      "\u001b[J6           0.676773    0.775908       0.71723               0.763635                  122.411       \n",
      "\u001b[J7           0.595303    0.803577       0.660464              0.786226                  142.669       \n",
      "\u001b[J8           0.531892    0.825444       0.594784              0.806031                  162.998       \n",
      "\u001b[J9           0.479396    0.841912       0.592715              0.810609                  183.328       \n",
      "\u001b[J10          0.429082    0.858115       0.583099              0.819467                  203.605       \n",
      "\u001b[J11          0.394583    0.871119       0.534827              0.834295                  223.952       \n",
      "\u001b[J12          0.361871    0.882242       0.554064              0.834992                  244.223       \n",
      "\u001b[J13          0.323018    0.891604       0.566799              0.833798                  264.517       \n",
      "\u001b[J14          0.301261    0.900448       0.546342              0.840864                  284.826       \n",
      "\u001b[J15          0.276494    0.90689        0.564172              0.843252                  305.07        \n",
      "\u001b[J16          0.253886    0.917013       0.513478              0.852607                  325.288       \n",
      "\u001b[J17          0.236839    0.921196       0.540844              0.851513                  345.591       \n",
      "\u001b[J18          0.215654    0.926937       0.56743               0.84793                   365.921       \n",
      "\u001b[J19          0.198961    0.934019       0.596954              0.848627                  386.18        \n",
      "\u001b[J20          0.186347    0.93886        0.584145              0.847731                  406.467       \n"
     ]
    }
   ],
   "source": [
    "from chainer.datasets import cifar\n",
    "from chainer import iterators\n",
    "from chainer import optimizers\n",
    "from chainer import training\n",
    "from chainer.training import extensions\n",
    "\n",
    "def train(model_class, batchsize=64, gpu_id=0, max_epoch=20):\n",
    "\n",
    "    # 1. Dataset\n",
    "    train, test = cifar.get_cifar10()\n",
    "\n",
    "    # 2. Iterator\n",
    "    train_iter = iterators.SerialIterator(train, batchsize)\n",
    "    test_iter = iterators.SerialIterator(test, batchsize, False, False)\n",
    "\n",
    "    # 3. Model\n",
    "    model = model_class(10)\n",
    "    model = L.Classifier(model)\n",
    "    model.to_gpu(gpu_id)\n",
    "\n",
    "    # 4. Optimizer\n",
    "    optimizer = optimizers.Adam()\n",
    "    optimizer.setup(model)\n",
    "\n",
    "    # 5. Updater\n",
    "    updater = training.StandardUpdater(train_iter, optimizer, device=gpu_id)\n",
    "\n",
    "    # 6. Trainer\n",
    "    trainer = training.Trainer(updater, (max_epoch, 'epoch'), out='cifar10_result')\n",
    "\n",
    "    # 7. Evaluator\n",
    "\n",
    "    class TestModeEvaluator(extensions.Evaluator):\n",
    "\n",
    "        def evaluate(self):\n",
    "            model = self.get_target('main')\n",
    "            model.train = False\n",
    "            ret = super(TestModeEvaluator, self).evaluate()\n",
    "            model.train = True\n",
    "            return ret\n",
    "\n",
    "    trainer.extend(extensions.LogReport())\n",
    "    trainer.extend(TestModeEvaluator(test_iter, model, device=gpu_id))\n",
    "    trainer.extend(extensions.PrintReport(['epoch', 'main/loss', 'main/accuracy', 'validation/main/loss', 'validation/main/accuracy', 'elapsed_time']))\n",
    "    trainer.extend(extensions.PlotReport(['main/loss', 'validation/main/loss'], x_key='epoch', file_name='loss.png'))\n",
    "    trainer.extend(extensions.PlotReport(['main/accuracy', 'validation/main/accuracy'], x_key='epoch', file_name='accuracy.png'))\n",
    "    trainer.run()\n",
    "    \n",
    "train(MyModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "学習が一通り終わりました。ロスと精度のプロットを見てみましょう。\n",
    "\n",
    "ロス：\n",
    "![](cifar10_result/loss.png)\n",
    "\n",
    "精度：\n",
    "![](cifar10_result/accuracy.png)\n",
    "\n",
    "学習データでの精度は98%近くまで到達していますが、テストデータではロスはむしろIterationを進むごとに大きくなってしまっており、また精度も60%付近で頭打ちになってしまっています。モデルが学習データにオーバーフィッティングしていると思われます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3. 学習済みモデルを使った予測\n",
    "\n",
    "テスト精度は60%程度でしたが、この学習済みモデルを使っていくつかのテスト画像を分類させてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cls_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "             'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "def predict(image_id):\n",
    "    x, t = test[image_id]\n",
    "    model.to_cpu()\n",
    "    y = model.predictor(x[None, ...]).data.argmax(axis=1)[0]\n",
    "    print('predicted_label:', cls_names[y])\n",
    "    print('answer:', cls_names[t])\n",
    "\n",
    "    plt.imshow(x.transpose(1, 2, 0))\n",
    "    plt.show()\n",
    "\n",
    "predict(0)\n",
    "predict(1)\n",
    "predict(2)\n",
    "predict(3)\n",
    "predict(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "うまく分類できているものもあれば、そうでないものもありました。モデルの学習に使用したデータセット上ではほぼ百発百中で正解できるとしても、未知のデータ、すなわちテストデータセットにある画像に対して高精度な予測ができなければ、意味がありません。テストデータでの精度は、モデルの**汎化性能**に関係していると言われます。\n",
    "\n",
    "どうすれば高い汎化性能を持つモデルを設計し、学習することができるでしょうか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvBlock(chainer.Chain):\n",
    "    \n",
    "    def __init__(self, n_ch, pool_drop=False):\n",
    "        w = chainer.initializers.HeNormal()\n",
    "        super(ConvBlock, self).__init__(\n",
    "            conv=L.Convolution2D(None, n_ch, 3, 1, 1,\n",
    "                                 nobias=True, initialW=w),\n",
    "            bn=L.BatchNormalization(n_ch)\n",
    "        )\n",
    "        \n",
    "        self.train = True\n",
    "        self.pool_drop = pool_drop\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.bn(self.conv(x)))\n",
    "        if self.pool_drop:\n",
    "            h = F.max_pooling_2d(h, 2, 2)\n",
    "            h = F.dropout(h, ratio=0.25, train=self.train)\n",
    "        return h\n",
    "    \n",
    "class LinearBlock(chainer.Chain):\n",
    "    \n",
    "    def __init__(self):\n",
    "        w = chainer.initializers.HeNormal()\n",
    "        super(LinearBlock, self).__init__(\n",
    "            fc=L.Linear(None, 1024, initialW=w))\n",
    "        self.train = True\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return F.dropout(F.relu(self.fc(x)), ratio=0.5, train=self.train)\n",
    "\n",
    "class CifarVGG(chainer.ChainList):\n",
    "\n",
    "    def __init__(self, n_output):\n",
    "        super(CifarVGG, self).__init__(\n",
    "            ConvBlock(64),\n",
    "            ConvBlock(64, True),\n",
    "            ConvBlock(128),\n",
    "            ConvBlock(128, True),\n",
    "            ConvBlock(256),\n",
    "            ConvBlock(256),\n",
    "            ConvBlock(256),\n",
    "            ConvBlock(256, True),\n",
    "            LinearBlock(),\n",
    "            LinearBlock(),\n",
    "            L.Linear(None, n_output)\n",
    "        )\n",
    "        self._train = True\n",
    "            \n",
    "    @property\n",
    "    def train(self):\n",
    "        return self._train\n",
    "            \n",
    "    @train.setter\n",
    "    def train(self, val):\n",
    "        self._train = val\n",
    "        for c in self.children():\n",
    "            c.train = val\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for f in self.children():\n",
    "            x = f(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
